{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Create connection...\n",
      "\n",
      "List connections:\n",
      "[('default', <pymilvus.client.grpc_handler.GrpcHandler object at 0x2b39b16f0>)]\n",
      "{'episode_id': [15740694059, 15740694059, 15740694059], 'text': ['Hallo und herzlich willkommen!', 'In der heutigen Sendung geht es noch einmal um language model programming languages.', 'Diesmal haben wir mit lookerbäurekäne und markfischer 2 Entwickler von LMQL'], 'start': [0.089, 1.63, 5.993], 'end': [1.63, 5.993, 12.497], 'speaker': ['unknown', 'unknown2', 'unknown1'], 'embeddings': array([[0.6378742 , 0.43925104, 0.13211584],\n",
      "       [0.46866668, 0.74429647, 0.03190612],\n",
      "       [0.31691246, 0.60253741, 0.90073872]])}\n",
      "    episode_id                                               text  start  \\\n",
      "0  15740694059                     Hallo und herzlich willkommen!  0.089   \n",
      "1  15740694059  In der heutigen Sendung geht es noch einmal um...   1.63   \n",
      "2  15740694059  Diesmal haben wir mit lookerbäurekäne und mark...  5.993   \n",
      "\n",
      "      end   speaker                                         embeddings  \n",
      "0    1.63   unknown  [0.6378742006852851, 0.43925103574669633, 0.13...  \n",
      "1   5.993  unknown2  [0.468666676812172, 0.744296470467782, 0.03190...  \n",
      "2  12.497  unknown1  [0.3169124582372903, 0.6025374094941409, 0.900...  \n",
      "Number of entities in DB: 3\n"
     ]
    }
   ],
   "source": [
    "# eigene Funtionen aus dem src-Ordner des übergeordneten Verzeichnis importieren\n",
    "import random\n",
    "import sys, os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "LIBPATH = os.path.abspath('../src')\n",
    "if not LIBPATH in sys.path: sys.path.insert(1, LIBPATH)\n",
    "import src.server.feed as feed\n",
    "import src.server.core as core\n",
    "#import src.server.service as service\n",
    "import src.server.db as db\n",
    "from dotenv import dotenv_values\n",
    "#\n",
    "import importlib\n",
    "#\n",
    "importlib.reload(core)\n",
    "importlib.reload(feed)\n",
    "importlib.reload(db)\n",
    "\n",
    "data_list = [\n",
    "    { 'id': 1, 'text': \"Hallo und herzlich willkommen!\",\n",
    "     'start': 0.089,\n",
    "     \"end\": 1.63,\n",
    "     'episode_id': 15740694059,\n",
    "     'speaker': 'unknown'\n",
    "     },\n",
    "    {'id': 2, 'text': \"In der heutigen Sendung geht es noch einmal um language model programming languages.\",\n",
    "     'start': 1.63,\n",
    "     'end': 5.993,\n",
    "     'episode_id': 15740694059,\n",
    "     'speaker': 'unknown2'\n",
    "     },\n",
    "    {'id': 3, 'text': \"Diesmal haben wir mit lookerbäurekäne und markfischer 2 Entwickler von LMQL\",\n",
    "     'start': 5.993,\n",
    "     'end': 12.497,\n",
    "     'episode_id': 15740694059,\n",
    "     'speaker': 'unknown1'\n",
    "     }\n",
    "]\n",
    "'''\n",
    "transcript_parsed = {\n",
    "    'id':  [obj[\"id\"] for obj in data_list],\n",
    "    'text':  [obj[\"text\"] for obj in data_list],\n",
    "    'start': [obj[\"start\"] for obj in data_list],\n",
    "    'end': [obj[\"end\"] for obj in data_list],\n",
    "    'episode_id': [obj[\"episode_id\"] for obj in data_list],\n",
    "    'speaker': [obj[\"speaker\"] for obj in data_list]\n",
    "}\n",
    "'''\n",
    "rng = np.random.default_rng(seed=19530)\n",
    "db.main(len(data_list))\n",
    "\n",
    "transcript_parsed = {\n",
    "    'episode_id': [obj[\"episode_id\"] for obj in data_list],\n",
    "    'text': [obj[\"text\"] for obj in data_list],\n",
    "    'start': [obj[\"start\"] for obj in data_list],\n",
    "    'end': [obj[\"end\"] for obj in data_list],\n",
    "    'speaker': [obj[\"speaker\"] for obj in data_list],\n",
    "    'embeddings': rng.random((len(data_list), len(data_list)))\n",
    "}\n",
    "\n",
    "df = pd.DataFrame.from_dict(transcript_parsed, orient='index')\n",
    "df = df.transpose()\n",
    "print(transcript_parsed)\n",
    "print(df)\n",
    "db.insert(\"segment\", df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T00:52:59.882959Z",
     "start_time": "2024-01-30T00:52:56.638445Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[array([0.1, 0.2, 0.3, 0. ]), array([0.4, 0.5, 0.6, 0.7]), array([0.8, 0.9, 0. , 0. ])]\n"
     ]
    }
   ],
   "source": [
    "vectors = [\n",
    "    [0.1, 0.2, 0.3],\n",
    "    [0.4, 0.5, 0.6, 0.7],\n",
    "    [0.8, 0.9],\n",
    "]\n",
    "\n",
    "max_dimension = max(len(vector) for vector in vectors)\n",
    "padded_vectors = [np.pad(vector, (0, max_dimension - len(vector))) for vector in vectors]\n",
    "print(max_dimension)\n",
    "print(padded_vectors)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T23:12:33.036999Z",
     "start_time": "2024-01-30T23:12:33.025524Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.39063188, 0.66886214, 0.50608562, 0.90396541, 0.87414003,\n        0.48108779, 0.        , 0.        , 0.        , 0.        ],\n       [0.79361495, 0.0714432 , 0.40819652, 0.04233087, 0.47465955,\n        0.42384023, 0.        , 0.        , 0.        , 0.        ],\n       [0.68811928, 0.99213754, 0.99466013, 0.9460857 , 0.3032171 ,\n        0.08543849, 0.        , 0.        , 0.        , 0.        ],\n       [0.82474042, 0.71266997, 0.50988795, 0.86818741, 0.1787267 ,\n        0.51033661, 0.        , 0.        , 0.        , 0.        ],\n       [0.91466688, 0.48731351, 0.86869211, 0.6577328 , 0.70518264,\n        0.00441141, 0.        , 0.        , 0.        , 0.        ],\n       [0.5929002 , 0.33290961, 0.8798359 , 0.4955251 , 0.04485436,\n        0.64679991, 0.        , 0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ]])"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = rng.random((6, 6))\n",
    "#vector\n",
    "max = 10\n",
    "sk = np.pad(vector, (0, max - len(vector)), 'constant', constant_values=0.0)\n",
    "sk#[0]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T00:22:20.227940Z",
     "start_time": "2024-01-31T00:22:20.215151Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T00:09:26.444117Z",
     "start_time": "2024-01-30T00:09:26.137893Z"
    }
   },
   "outputs": [],
   "source": [
    "config = dotenv_values(\"../.env\")\n",
    "podcasts = feed.search_podcast('Knowledge Science - Alles über KI, ML und NLP', config=config)\n",
    "#podcasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-29T22:48:07.907426Z"
    }
   },
   "outputs": [],
   "source": [
    "podcast_id = podcasts['feeds'][0]['id']\n",
    "podcast_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-29T22:48:07.908700Z"
    }
   },
   "outputs": [],
   "source": [
    "episodes = feed.get_episodes(podcast_id, config=config)\n",
    "\n",
    "for episode in episodes[0:min(5, len(episodes))]:\n",
    "    print(episode['enclosureUrl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-29T22:48:07.910027Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://podcastindex.org/podcast/2481152?episode=15580091589\n",
    "# https://radioplus-bloomberg.akamaized.net/syndicatedaudio/MarketMinutesWeekday.mp3\n",
    "#episode_id, episode_url = '2334', 'https://radioplus-bloomberg.akamaized.net/syndicatedaudio/MarketMinutesWeekday.mp3'\n",
    "episode_id, episode_url= episodes[0]['id'], episodes[0]['enclosureUrl']\n",
    "episodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-29T22:48:07.911551Z"
    }
   },
   "outputs": [],
   "source": [
    "filename_audio = feed.download_episode(episode_url, episode_id=episode_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2024-01-29T22:48:07.914526Z"
    }
   },
   "outputs": [],
   "source": [
    "(filename_transcript, transcript) = core.transcribe(episode_id, filename_audio, diarize=False) # , language='de'\n",
    "transcript_parsed = transcript['parsed_transcript']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Connection established')\n",
    "import importlib\n",
    "importlib.reload(db)\n",
    "dim=4\n",
    "\n",
    "podcast = pd.DataFrame([{\n",
    "    'id': 1234,\n",
    "    'title': 'Knowledge Science - Alles über KI, ML und NLP',\n",
    "    'embeddings': rng.random((1, 4))[0],\n",
    "    'description': 'Knowledge Science - Der Podcast über Künstliche Intelligenz im Allgemeinen und Natural Language Processing im Speziellen. Mittels KI Wissen entdecken, aufbereiten und nutzbar machen, dass ist die Idee hinter Knowledge Science. Durch Entmystifizierung der Künstlichen Intelligenz und vielen praktischen Interviews machen wir dieses Thema wöchentlich greifbar.',\n",
    "    'author': 'Sigurd Schacht, Carsten Lanquillon',\n",
    "    'image': 'https://storage.buzzsprout.com/variants/3y8i7tuyi2gq6bj2d3dvlorswfu7/5cfec01b44f3e29fae1fb88ade93fc4aecd05b192fbfbc2c2f1daa412b7c1921.jpg',\n",
    "    'language': 'de',\n",
    "    'url': 'https://feeds.buzzsprout.com/1687822.rss',\n",
    "    'episodeCount': 106\n",
    "}])\n",
    "\n",
    "db.insert(\"podcast\", podcast)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-01-29T22:48:07.930765Z",
     "start_time": "2024-01-29T22:48:07.915780Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rng.random((1, 4))[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-29T22:48:07.916822Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#\n",
    "episode = pd.DataFrame([{\n",
    "    'id': 15740694059,\n",
    "    'title': 'Episode 107 - Red-Teaming & Jailbreaking',\n",
    "    'description': 'p>In der aktuellen Sendung des neuen Jahres starten wir mit einem spannenden Thema zum Jailbreaking und Red-Teaming von Sprachmodellen. Bleiben Sie dran.<br/><br/>Vielen Dank auch an unseren Sponsor XL2:\\xa0<br/><br/>XL2 ist ein Joint Venture von Audi und Capgemini,\\xa0<br/>dass die digitale Transformation in der Automobilindustrie vorantreibt. Das Unternehmen\\xa0erarbeitet innovative End-to-End-Prozesse und implementiert maßgeschneiderte IT-Lösungen für seine Kunden.</p>Support the show',\n",
    "    'datePublishedPretty': 'January 13, 2024 1:00pm',\n",
    "    'image': 'https://storage.buzzsprout.com/variants/8zwtzsw47ln492vgbhgbmszq7reu/60854458c4d1acdf4e1c2f79c4137142d85d78e379bdafbd69bd34c85f5819ad.jpg',\n",
    "    'enclosureUrl': 'https://www.buzzsprout.com/1687822/14302036-episode-107-red-teaming-jailbreaking.mp3',\n",
    "    'podcast_id': 1234,\n",
    "    'embeddings': rng.random((1, dim))[0]\n",
    "}])\n",
    "\n",
    "db.insert(\"episode\", episode)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-29T22:48:07.917430Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " df_transcript_segments = pd.DataFrame()\n",
    " df_transcript_segments['embeddings'] = rng.random((1, 4))\n",
    "len(df_transcript_segments)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-29T22:48:07.918149Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-29T22:48:07.919061Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "transcript_parsed = pd.DataFrame([\n",
    "    {\n",
    "        'episode_id': 15740694059,\n",
    "        'id': 00,\n",
    "        'embeddings': rng.random((1, dim))[0],\n",
    "        'speaker': 'unknown', 'start': 0.089,\n",
    "        'end': 1.63,\n",
    "        'text': ' Hallo und herzlich willkommen!',\n",
    "    },\n",
    "    {\n",
    "        'embeddings': rng.random((1, dim))[0],'speaker': 'unknown', 'start': 1.63, 'end': 5.993, 'text': 'In der heutigen Sendung geht es noch einmal um language model programming languages.', 'episode': 15740694059},\n",
    "    {\n",
    "        'embeddings': rng.random((1, dim))[0],\n",
    "        'speaker': 'unknown', 'start': 5.993, 'end': 12.497,\n",
    "        'text': 'Diesmal haben wir mit lookerbäurekäne und markfischer 2 Entwickler von LMQL der language model query language zu Gast.', 'episode': 15740694059},\n",
    "    {'embeddings': rng.random((1, dim))[0],'speaker': 'unknown', 'start': 12.497, 'end': 19.361, 'text': 'Die uns spannende Einblicke in die Entstehungsgeschichte und Fähigkeiten von LMQL und mögliche Weiterentwicklung geben werden.', 'episode': 15740694059},\n",
    "    {'embeddings': rng.random((1, dim))[0],'speaker': 'unknown', 'start': 19.361, 'end': 24.404, 'text': 'Auch diese Sendung wird von XZ2 dem Joint Venture von Audi und Cup Gemini gesponsat.', 'episode': 15740694059}\n",
    "])\n",
    "\n",
    "db.insert(\"segment\", transcript_parsed)\n",
    "'''\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2024-01-29T22:48:07.919521Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "db.get_collection_data('segment')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2024-01-29T22:48:07.920775Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_dimension = max(len(vector) for vector in vectors)\n",
    "padded_vectors = [np.pad(vector, (0, max_dimension - len(vector))) for vector in vectors]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
