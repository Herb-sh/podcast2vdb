{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/herbishtini/anaconda3/envs/whisperx/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "german.model: 100%|██████████| 738M/738M [01:49<00:00, 6.73MB/s] \n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format(hf_hub_download(repo_id=\"Word2vec/german_model\", filename=\"german.model\"), binary=True, unicode_errors=\"ignore\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T23:17:29.995253Z",
     "start_time": "2024-03-06T23:15:25.428851Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.59018481e-01  4.34756167e-02 -2.66063958e-01  3.77931029e-01\n",
      "  1.10136062e-01 -8.98484215e-02  1.89175121e-02  3.29087824e-01\n",
      " -1.28299698e-01  4.63936925e-02  1.45522133e-01 -1.03230573e-01\n",
      " -5.00932150e-02  3.42555165e-01 -9.81640220e-02 -2.55089164e-01\n",
      " -1.84677124e-01 -2.35522494e-01  3.56340498e-01 -2.13016674e-01\n",
      " -1.45755038e-01 -1.04607038e-01  1.16282605e-01  8.31777230e-02\n",
      " -8.15125927e-02  2.70997155e-02  7.89255440e-01 -1.59523740e-01\n",
      " -1.19426183e-01 -1.12738639e-01 -1.32015675e-01 -3.05022925e-01\n",
      "  6.43652901e-02 -1.31135732e-02 -3.24149698e-01  2.76411444e-01\n",
      " -4.23725337e-01 -1.59848675e-01 -2.82887250e-01  8.75200257e-02\n",
      " -5.24234287e-02  7.39130145e-03 -4.61482167e-01  2.58865148e-01\n",
      " -2.51074824e-02 -5.24699509e-01  2.62916833e-01  1.53730974e-01\n",
      "  1.84853122e-01 -1.34917855e-01  2.02824082e-02 -9.49798990e-03\n",
      "  2.62115359e-01 -1.44494161e-01  1.35141417e-01  2.62386110e-02\n",
      "  2.20654905e-01 -1.20826840e-01 -1.63558245e-01 -8.21780190e-02\n",
      "  4.07639861e-01 -1.20738028e-02 -4.48412627e-01 -8.07543844e-02\n",
      "  1.39067814e-01  2.29443669e-01  9.83124077e-02  1.36044636e-01\n",
      "  2.33746290e-01 -1.30840635e-03 -2.05481514e-01  5.27452342e-02\n",
      " -2.10511729e-01  9.82275605e-03  1.54086813e-01 -5.77348582e-02\n",
      " -1.02445595e-01 -2.67246217e-01 -1.37372524e-01 -4.01713792e-03\n",
      " -5.83628893e-01  5.54960780e-02 -9.07692909e-02  9.23452973e-02\n",
      "  5.22106528e-01 -2.61178523e-01 -5.80343127e-04 -2.72086024e-01\n",
      " -4.86779213e-02  5.47638647e-02 -6.45636976e-01  1.00728363e-01\n",
      " -3.16045046e-01  2.71903843e-01 -3.82642411e-02  4.13213134e-01\n",
      " -4.61931258e-01  1.81785762e-01 -1.96742490e-02 -2.77164225e-02\n",
      " -1.26083985e-01  1.05098389e-01 -3.30432266e-01 -2.53341109e-01\n",
      "  1.61256686e-01  1.06451884e-02  6.66038767e-02 -2.27575853e-01\n",
      "  2.45485338e-03  4.01793271e-01  3.11285555e-01 -2.35452339e-01\n",
      "  4.05553691e-02  8.79605785e-02  3.55190367e-01 -5.40613085e-02\n",
      "  2.24534664e-02 -1.98284626e-01 -1.83695570e-01  8.74442756e-02\n",
      " -7.49394298e-02 -3.00723940e-01  2.99944729e-01 -1.68384120e-01\n",
      "  3.29817384e-01 -9.80765820e-02  4.33222465e-02 -1.26596227e-01\n",
      "  5.52638650e-01 -2.79832006e-01  3.41193348e-01 -8.30412582e-02\n",
      "  3.97735327e-01 -1.96871445e-01 -2.09530190e-01  1.14146672e-01\n",
      "  2.41039380e-01 -9.56824198e-02  3.44857313e-02  4.71090488e-02\n",
      " -3.67774218e-02  1.67257324e-01  2.33373329e-01 -4.18378450e-02\n",
      "  3.50609452e-01 -4.17959392e-02 -1.17746182e-01 -9.08007920e-02\n",
      "  2.19549283e-01  2.71588236e-01 -3.09128851e-01 -5.35451509e-02\n",
      "  8.95828307e-02  2.56098360e-01 -5.05124480e-02 -1.36645138e-03\n",
      " -1.65706620e-01 -2.28828058e-01  3.22590917e-01  1.61698118e-01\n",
      "  1.05681717e-01  1.53645530e-01  1.86158136e-01  8.09438005e-02\n",
      "  1.91905141e-01 -5.73710091e-02 -2.46398702e-01 -2.27528010e-02\n",
      " -1.74647391e-01 -5.96159220e-01 -2.69551147e-02 -7.22468868e-02\n",
      " -1.63055837e-01 -1.14668369e-01  1.16885126e-01 -1.52405441e-01\n",
      " -2.66417772e-01 -1.90200612e-01  2.32379600e-01  1.96537927e-01\n",
      "  5.63951731e-02  2.06819043e-01  2.22905710e-01 -2.75125414e-01\n",
      " -1.74209967e-01 -3.19528371e-01 -3.10422391e-01 -3.76919180e-01\n",
      "  1.18744142e-01 -5.63447215e-02 -1.10665418e-01  7.52603030e-03\n",
      "  2.83366665e-02 -2.54323989e-01  1.26545072e-01  1.80511117e-01\n",
      " -2.77059823e-01  3.42531689e-02 -6.92853630e-02  1.12439901e-01\n",
      "  3.83247398e-02  8.25411379e-02 -1.19040422e-01 -1.76598549e-01\n",
      "  4.79260646e-02  1.44215122e-01 -5.71310818e-01 -2.49199510e-01\n",
      " -4.57279593e-01  2.68928200e-01  1.86557636e-01  2.52580494e-01\n",
      "  5.04202656e-02 -7.35520497e-02 -4.90245111e-02 -2.15154871e-01\n",
      " -1.07694119e-02 -1.39035536e-02 -2.01783106e-01  2.49875128e-01\n",
      " -8.07800889e-02 -2.89633155e-01 -2.84559522e-02 -2.69172937e-01\n",
      " -3.13509852e-01  7.95875397e-03  1.13085799e-01  3.26003700e-01\n",
      "  9.50074792e-02  2.74279743e-01 -8.67484137e-02  3.10461372e-02\n",
      "  2.49015257e-01  3.25519335e-03  3.37140001e-02 -5.06738434e-03\n",
      "  2.70548370e-02 -2.53993779e-01 -4.59792376e-01  5.87936342e-02\n",
      "  8.74154344e-02  1.14208631e-01 -8.75318721e-02  3.10305953e-01\n",
      "  7.40830377e-02  6.42444491e-02  1.00552261e-01 -4.57968324e-01\n",
      "  5.11387289e-02 -2.80640530e-03 -7.44794905e-02  1.53782383e-01\n",
      " -3.51976037e-01  3.31285745e-01  3.44394483e-02  2.44890854e-01\n",
      " -4.84835990e-02 -1.89041913e-01 -1.28625587e-01  1.29991248e-01\n",
      "  7.80105591e-03  9.96219739e-02 -8.17857012e-02 -1.02097280e-02\n",
      "  3.61950584e-02  8.67836401e-02 -9.37620401e-02  4.04189825e-01\n",
      " -1.80192277e-01 -3.78071159e-01  2.04366013e-01  3.23924661e-01\n",
      " -1.13000415e-01 -3.95146489e-01 -5.38245402e-02  2.57545322e-01\n",
      " -9.48941410e-02  2.07214262e-02 -5.38164116e-02 -1.44006535e-01\n",
      " -1.43321842e-01 -6.76748455e-02 -1.74406692e-01 -2.18992293e-01\n",
      " -2.07048729e-01  1.73654154e-01  6.44529760e-02 -1.34071067e-01\n",
      " -4.65413816e-02  1.38049514e-03 -3.73870373e-01 -3.51738594e-02\n",
      "  1.82711020e-01  3.05851966e-01 -2.11053610e-01 -1.32231995e-01\n",
      " -1.38397217e-02 -1.31387219e-01 -4.68443073e-02 -4.41526212e-02]\n"
     ]
    }
   ],
   "source": [
    "def embed_text(text, model):\n",
    "    words = text.split()\n",
    "    # Filter out words not in the vocabulary\n",
    "    words_in_vocab = [word for word in words if word in model]\n",
    "    if not words_in_vocab:\n",
    "        return None  # If no words in vocabulary, return None or handle accordingly\n",
    "    # Calculate the mean of word vectors\n",
    "    embedding = sum(model[word] for word in words_in_vocab) / len(words_in_vocab)\n",
    "    return embedding\n",
    "\n",
    "text_to_embed = \"This is an example text.\"\n",
    "embedding = embed_text(text_to_embed, model)\n",
    "print(embedding)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T23:18:54.458274Z",
     "start_time": "2024-03-06T23:18:54.441819Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_full_repo_name' from 'huggingface_hub' (/Users/herbishtini/anaconda3/envs/whisperx/lib/python3.10/site-packages/huggingface_hub/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoTokenizer, AutoModel\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Load pre-trained BERT model and tokenizer\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/whisperx/lib/python3.10/site-packages/transformers/__init__.py:26\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TYPE_CHECKING\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001B[39;00m\n\u001B[0;32m---> 26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dependency_versions_check\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     28\u001B[0m     OptionalDependencyNotAvailable,\n\u001B[1;32m     29\u001B[0m     _LazyModule,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     46\u001B[0m     logging,\n\u001B[1;32m     47\u001B[0m )\n\u001B[1;32m     50\u001B[0m logger \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mget_logger(\u001B[38;5;18m__name__\u001B[39m)  \u001B[38;5;66;03m# pylint: disable=invalid-name\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/whisperx/lib/python3.10/site-packages/transformers/dependency_versions_check.py:16\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# See the License for the specific language governing permissions and\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdependency_versions_table\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m deps\n\u001B[0;32m---> 16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mversions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m require_version, require_version_core\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# define which module versions we always want to check at run time\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# order specific notes:\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# - tqdm must be checked before tokenizers\u001B[39;00m\n\u001B[1;32m     25\u001B[0m pkgs_to_check_at_runtime \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpython\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     27\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtqdm\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpyyaml\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     38\u001B[0m ]\n",
      "File \u001B[0;32m~/anaconda3/envs/whisperx/lib/python3.10/site-packages/transformers/utils/__init__.py:18\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#!/usr/bin/env python\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# coding=utf-8\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# See the License for the specific language governing permissions and\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[0;32m---> 18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mhuggingface_hub\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_full_repo_name  \u001B[38;5;66;03m# for backward compatibility\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpackaging\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m version\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m __version__\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'get_full_repo_name' from 'huggingface_hub' (/Users/herbishtini/anaconda3/envs/whisperx/lib/python3.10/site-packages/huggingface_hub/__init__.py)"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Example text\n",
    "text = \"This is an example text to embed.\"\n",
    "\n",
    "# Tokenize and encode the text\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Forward pass through the BERT model\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Extract the embeddings from the last hidden layer\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "# Mean pooling of the last hidden layer to get a single vector for the entire text\n",
    "bert_embedding = last_hidden_states.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "# Display the BERT embedding\n",
    "print(bert_embedding)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T22:13:46.253066Z",
     "start_time": "2024-03-06T22:13:45.953638Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Create connection...\n",
      "\n",
      "List connections:\n",
      "[('default', <pymilvus.client.grpc_handler.GrpcHandler object at 0x2b39b16f0>)]\n",
      "{'episode_id': [15740694059, 15740694059, 15740694059], 'text': ['Hallo und herzlich willkommen!', 'In der heutigen Sendung geht es noch einmal um language model programming languages.', 'Diesmal haben wir mit lookerbäurekäne und markfischer 2 Entwickler von LMQL'], 'start': [0.089, 1.63, 5.993], 'end': [1.63, 5.993, 12.497], 'speaker': ['unknown', 'unknown2', 'unknown1'], 'embeddings': array([[0.6378742 , 0.43925104, 0.13211584],\n",
      "       [0.46866668, 0.74429647, 0.03190612],\n",
      "       [0.31691246, 0.60253741, 0.90073872]])}\n",
      "    episode_id                                               text  start  \\\n",
      "0  15740694059                     Hallo und herzlich willkommen!  0.089   \n",
      "1  15740694059  In der heutigen Sendung geht es noch einmal um...   1.63   \n",
      "2  15740694059  Diesmal haben wir mit lookerbäurekäne und mark...  5.993   \n",
      "\n",
      "      end   speaker                                         embeddings  \n",
      "0    1.63   unknown  [0.6378742006852851, 0.43925103574669633, 0.13...  \n",
      "1   5.993  unknown2  [0.468666676812172, 0.744296470467782, 0.03190...  \n",
      "2  12.497  unknown1  [0.3169124582372903, 0.6025374094941409, 0.900...  \n",
      "Number of entities in DB: 3\n"
     ]
    }
   ],
   "source": [
    "# eigene Funtionen aus dem src-Ordner des übergeordneten Verzeichnis importieren\n",
    "import sys, os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "LIBPATH = os.path.abspath('../src')\n",
    "if not LIBPATH in sys.path: sys.path.insert(1, LIBPATH)\n",
    "import src.server.feed as feed\n",
    "import src.server.core as core\n",
    "import src.server.db as db\n",
    "from dotenv import dotenv_values\n",
    "#\n",
    "from gensim.models import Word2Vec\n",
    "#\n",
    "import importlib\n",
    "#\n",
    "importlib.reload(core)\n",
    "importlib.reload(feed)\n",
    "importlib.reload(db)\n",
    "\n",
    "data_list = [\n",
    "    { 'id': 1, 'text': \"Hallo und herzlich willkommen!\",\n",
    "     'start': 0.089,\n",
    "     \"end\": 1.63,\n",
    "     'episode_id': 15740694059,\n",
    "     'speaker': 'unknown'\n",
    "     },\n",
    "    {'id': 2, 'text': \"In der heutigen Sendung geht es noch einmal um language model programming languages.\",\n",
    "     'start': 1.63,\n",
    "     'end': 5.993,\n",
    "     'episode_id': 15740694059,\n",
    "     'speaker': 'unknown2'\n",
    "     },\n",
    "    {'id': 3, 'text': \"Diesmal haben wir mit lookerbäurekäne und markfischer 2 Entwickler von LMQL\",\n",
    "     'start': 5.993,\n",
    "     'end': 12.497,\n",
    "     'episode_id': 15740694059,\n",
    "     'speaker': 'unknown1'\n",
    "     }\n",
    "]\n",
    "'''\n",
    "transcript_parsed = {\n",
    "    'id':  [obj[\"id\"] for obj in data_list],\n",
    "    'text':  [obj[\"text\"] for obj in data_list],\n",
    "    'start': [obj[\"start\"] for obj in data_list],\n",
    "    'end': [obj[\"end\"] for obj in data_list],\n",
    "    'episode_id': [obj[\"episode_id\"] for obj in data_list],\n",
    "    'speaker': [obj[\"speaker\"] for obj in data_list]\n",
    "}\n",
    "'''\n",
    "rng = np.random.default_rng(seed=19530)\n",
    "db.main(len(data_list))\n",
    "\n",
    "transcript_parsed = {\n",
    "    'episode_id': [obj[\"episode_id\"] for obj in data_list],\n",
    "    'text': [obj[\"text\"] for obj in data_list],\n",
    "    'start': [obj[\"start\"] for obj in data_list],\n",
    "    'end': [obj[\"end\"] for obj in data_list],\n",
    "    'speaker': [obj[\"speaker\"] for obj in data_list],\n",
    "    'embeddings': rng.random((len(data_list), len(data_list)))\n",
    "}\n",
    "\n",
    "df = pd.DataFrame.from_dict(transcript_parsed, orient='index')\n",
    "df = df.transpose()\n",
    "print(transcript_parsed)\n",
    "print(df)\n",
    "db.insert(\"segment\", df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T00:52:59.882959Z",
     "start_time": "2024-01-30T00:52:56.638445Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.08848347]])"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng.random((1, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T23:05:07.331490Z",
     "start_time": "2024-02-06T23:05:07.313293Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T00:09:26.444117Z",
     "start_time": "2024-01-30T00:09:26.137893Z"
    }
   },
   "outputs": [],
   "source": [
    "config = dotenv_values(\"../.env\")\n",
    "podcasts = feed.search_podcast('Knowledge Science - Alles über KI, ML und NLP', config=config)\n",
    "#podcasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-29T22:48:07.907426Z"
    }
   },
   "outputs": [],
   "source": [
    "podcast_id = podcasts['feeds'][0]['id']\n",
    "podcast_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-29T22:48:07.908700Z"
    }
   },
   "outputs": [],
   "source": [
    "episodes = feed.get_episodes(podcast_id, config=config)\n",
    "\n",
    "for episode in episodes[0:min(5, len(episodes))]:\n",
    "    print(episode['enclosureUrl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-29T22:48:07.910027Z"
    }
   },
   "outputs": [],
   "source": [
    "episode_id, episode_url= episodes[0]['id'], episodes[0]['enclosureUrl']\n",
    "episodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-29T22:48:07.911551Z"
    }
   },
   "outputs": [],
   "source": [
    "filename_audio = feed.download_episode(episode_url, episode_id=episode_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2024-01-29T22:48:07.914526Z"
    }
   },
   "outputs": [],
   "source": [
    "(filename_transcript, transcript) = core.transcribe(episode_id, filename_audio, diarize=False) # , language='de'\n",
    "transcript_parsed = transcript['parsed_transcript']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(db)\n",
    "dim=4\n",
    "\n",
    "podcast = pd.DataFrame([{\n",
    "    'id': 1234,\n",
    "    'title': 'Knowledge Science - Alles über KI, ML und NLP',\n",
    "    'embeddings': rng.random((1, 4))[0],\n",
    "    'description': 'Knowledge Science - Der Podcast über Künstliche Intelligenz im Allgemeinen und Natural Language Processing im Speziellen. Mittels KI Wissen entdecken, aufbereiten und nutzbar machen, dass ist die Idee hinter Knowledge Science. Durch Entmystifizierung der Künstlichen Intelligenz und vielen praktischen Interviews machen wir dieses Thema wöchentlich greifbar.',\n",
    "    'author': 'Sigurd Schacht, Carsten Lanquillon',\n",
    "    'image': 'https://storage.buzzsprout.com/variants/3y8i7tuyi2gq6bj2d3dvlorswfu7/5cfec01b44f3e29fae1fb88ade93fc4aecd05b192fbfbc2c2f1daa412b7c1921.jpg',\n",
    "    'language': 'de',\n",
    "    'url': 'https://feeds.buzzsprout.com/1687822.rss',\n",
    "    'episodeCount': 106\n",
    "}])\n",
    "\n",
    "db.insert(\"podcast\", podcast)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-01-29T22:48:07.930765Z",
     "start_time": "2024-01-29T22:48:07.915780Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rng.random((1, 4))[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-29T22:48:07.916822Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#\n",
    "episode = pd.DataFrame([{\n",
    "    'id': 15740694059,\n",
    "    'title': 'Episode 107 - Red-Teaming & Jailbreaking',\n",
    "    'description': 'p>In der aktuellen Sendung des neuen Jahres starten wir mit einem spannenden Thema zum Jailbreaking und Red-Teaming von Sprachmodellen. Bleiben Sie dran.<br/><br/>Vielen Dank auch an unseren Sponsor XL2:\\xa0<br/><br/>XL2 ist ein Joint Venture von Audi und Capgemini,\\xa0<br/>dass die digitale Transformation in der Automobilindustrie vorantreibt. Das Unternehmen\\xa0erarbeitet innovative End-to-End-Prozesse und implementiert maßgeschneiderte IT-Lösungen für seine Kunden.</p>Support the show',\n",
    "    'datePublishedPretty': 'January 13, 2024 1:00pm',\n",
    "    'image': 'https://storage.buzzsprout.com/variants/8zwtzsw47ln492vgbhgbmszq7reu/60854458c4d1acdf4e1c2f79c4137142d85d78e379bdafbd69bd34c85f5819ad.jpg',\n",
    "    'enclosureUrl': 'https://www.buzzsprout.com/1687822/14302036-episode-107-red-teaming-jailbreaking.mp3',\n",
    "    'podcast_id': 1234,\n",
    "    'embeddings': rng.random((1, dim))[0]\n",
    "}])\n",
    "\n",
    "db.insert(\"episode\", episode)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-29T22:48:07.917430Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_transcript_segments = pd.DataFrame()\n",
    "df_transcript_segments['embeddings'] = rng.random((1, 4))\n",
    "len(df_transcript_segments)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-29T22:48:07.918149Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "transcript_parsed = pd.DataFrame([\n",
    "    {\n",
    "        'episode_id': 15740694059,\n",
    "        'id': 00,\n",
    "        'embeddings': rng.random((1, dim))[0],\n",
    "        'speaker': 'unknown', 'start': 0.089,\n",
    "        'end': 1.63,\n",
    "        'text': ' Hallo und herzlich willkommen!',\n",
    "    },\n",
    "    {\n",
    "        'embeddings': rng.random((1, dim))[0],'speaker': 'unknown', 'start': 1.63, 'end': 5.993, 'text': 'In der heutigen Sendung geht es noch einmal um language model programming languages.', 'episode': 15740694059},\n",
    "    {\n",
    "        'embeddings': rng.random((1, dim))[0],\n",
    "        'speaker': 'unknown', 'start': 5.993, 'end': 12.497,\n",
    "        'text': 'Diesmal haben wir mit lookerbäurekäne und markfischer 2 Entwickler von LMQL der language model query language zu Gast.', 'episode': 15740694059},\n",
    "    {'embeddings': rng.random((1, dim))[0],'speaker': 'unknown', 'start': 12.497, 'end': 19.361, 'text': 'Die uns spannende Einblicke in die Entstehungsgeschichte und Fähigkeiten von LMQL und mögliche Weiterentwicklung geben werden.', 'episode': 15740694059},\n",
    "    {'embeddings': rng.random((1, dim))[0],'speaker': 'unknown', 'start': 19.361, 'end': 24.404, 'text': 'Auch diese Sendung wird von XZ2 dem Joint Venture von Audi und Cup Gemini gesponsat.', 'episode': 15740694059}\n",
    "])\n",
    "\n",
    "db.insert(\"segment\", transcript_parsed)\n",
    "'''\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2024-01-29T22:48:07.919521Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "db.get_collection_data('segment')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2024-01-29T22:48:07.920775Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#max_dimension = max(len(vector) for vector in vectors)\n",
    "#padded_vectors = [np.pad(vector, (0, max_dimension - len(vector))) for vector in vectors]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
